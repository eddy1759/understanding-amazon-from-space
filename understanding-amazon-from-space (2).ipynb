{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd\nimport tensorflow as tf\nfrom tqdm import tqdm # To read in images in batches and see progress\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split # For the creation of training and validation sets\nfrom keras import optimizers\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, Dropout, Flatten\nfrom keras.layers import Conv2D,MaxPooling2D, BatchNormalization\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint \nfrom keras.preprocessing.image import ImageDataGenerator  #Used for Data augmentation\nfrom keras import backend as K   #For specialized and optimized tensor manipulation\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array","metadata":{"execution":{"iopub.status.busy":"2021-10-19T23:51:23.855248Z","iopub.execute_input":"2021-10-19T23:51:23.855910Z","iopub.status.idle":"2021-10-19T23:51:29.112247Z","shell.execute_reply.started":"2021-10-19T23:51:23.855815Z","shell.execute_reply":"2021-10-19T23:51:29.111298Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def create_tag_mapping(labels_df):\n    labels = set()\n    for i in range(len(labels_df)):\n        # convert spaced separated tags into an array of tags\n        tags = labels_df['tags'][i].split(' ')\n        # add tags to the set of known labels\n        labels.update(tags)\n    # convert set of labels to a list to list\n    labels = list(labels)\n    labels.sort()\n # dict that maps labels to integers, and the reverse\n    labels_map = { labels [i]:i for i in range(len(labels))}\n    inv_labels_map = {i: labels [i] for i in range(len(labels))}\n    return labels_map, inv_labels_map\n\n\n\ndef create_file_mapping(train_data):\n    mapping = dict()\n    for i in range(len(labels_df)):\n        name, tags = train_data['image_name'][i], labels_df['tags'][i]\n        mapping[name] = tags.split(' ')   \n    return mapping\n\n\ndef one_hot_encode(tags,mapping):\n    # create empty vector\n    encoding = np.zeros(len(mapping), dtype='uint8')\n    # mark 1 for each tag in the vector\n    for tag in tags:\n        encoding[mapping[tag]] = 1\n    return encoding\n\n\ndef load_dataset(path, file_mapping, tag_mapping):\n    photos, targets = list(), list()\n    # enumerate files in the directory\n    for filename in os.listdir(folder):\n        # load image\n        photo = load_img(path + filename, target_size=(64,64))\n        # convert to numpy array\n        photo = img_to_array(photo, dtype='uint8')\n        # get tags\n        tags = file_mapping[filename[:-4]]\n        # one hot encode tags\n        target = one_hot_encode(tags, tag_mapping)\n        # store\n        photos.append(photo)\n        targets.append(target)\n    X = np.asarray(photos, dtype='uint8')\n    y = np.asarray(targets, dtype='uint8')\n    return X, y\n    del photo\n    del targets","metadata":{"execution":{"iopub.status.busy":"2021-10-19T23:54:16.947311Z","iopub.execute_input":"2021-10-19T23:54:16.947898Z","iopub.status.idle":"2021-10-19T23:54:16.961123Z","shell.execute_reply.started":"2021-10-19T23:54:16.947851Z","shell.execute_reply":"2021-10-19T23:54:16.960072Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from keras import backend\n\ndef fbeta_score(y_true, y_pred, beta=2):\n    # clip predictions\n    y_pred = backend.clip(y_pred, 0, 1)\n    # calculate elements\n    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n    # calculate precision\n    p = tp / (tp + fp + backend.epsilon())\n    # calculate recall\n    r = tp / (tp + fn + backend.epsilon())\n    # calculate fbeta, averaged across each class\n    bb = beta ** 2\n    fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n    return fbeta_score","metadata":{"execution":{"iopub.status.busy":"2021-10-19T23:54:27.559437Z","iopub.execute_input":"2021-10-19T23:54:27.560046Z","iopub.status.idle":"2021-10-19T23:54:27.567188Z","shell.execute_reply.started":"2021-10-19T23:54:27.560006Z","shell.execute_reply":"2021-10-19T23:54:27.566317Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"filename = '../input/planets-dataset/planet/planet/train_classes.csv'\nlabels_df = pd.read_csv(filename)\n\n# create a mapping of tags to integers\nmapping, inv_mapping = create_tag_mapping(labels_df)\nprint(len(mapping))\n\n# create a mapping of tags to integers\ntag_mapping, _ = create_tag_mapping(labels_df)\n\n# create a mapping of filenames to tag lists\nfile_mapping = create_file_mapping(labels_df)\n\n# load the jpeg images\nfolder = '../input/planets-dataset/planet/planet/train-jpg/'\nX, y = load_dataset(folder, file_mapping, tag_mapping)\nprint(X.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-19T23:58:02.235593Z","iopub.execute_input":"2021-10-19T23:58:02.235857Z","iopub.status.idle":"2021-10-20T00:00:10.018809Z","shell.execute_reply.started":"2021-10-19T23:58:02.235828Z","shell.execute_reply":"2021-10-20T00:00:10.018054Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"unique_labels = set()\ndef append_labels(tags):\n    for tag in tags.split():\n        unique_labels.add(tag)\n\ntrain_classes = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\ntrain_classes['tags'].apply(append_labels)\nunique_labels = list(unique_labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:00:10.020531Z","iopub.execute_input":"2021-10-20T00:00:10.020790Z","iopub.status.idle":"2021-10-20T00:00:10.063927Z","shell.execute_reply.started":"2021-10-20T00:00:10.020754Z","shell.execute_reply":"2021-10-20T00:00:10.063282Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:01:22.014742Z","iopub.execute_input":"2021-10-20T00:01:22.015523Z","iopub.status.idle":"2021-10-20T00:01:22.203959Z","shell.execute_reply.started":"2021-10-20T00:01:22.015483Z","shell.execute_reply":"2021-10-20T00:01:22.203228Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_folder = '../input/planets-dataset/planet/planet/'\ntest = test_folder + 'sample_submission.csv'\ntest_df = pd.read_csv(test)\n\nx_test = []\n\ntest_img_folder = '../input/planets-dataset/planet/planet/test-jpg'\ntest_img_names = os.listdir(test_img_folder)\n\nn_test = len(test_img_names)\ntest_classes = test_df.iloc[:n_test, :]\nadd_classes = test_df.iloc[n_test:, :]\n\n\ntest_img_add_folder = '../input/planets-dataset/test-jpg-additional/test-jpg-additional'\ntest_add_img_names = os.listdir(test_img_add_folder)\n\nfor img_name, _ in tqdm(test_classes.values, miniters=1000):\n    img = cv2.resize(cv2.imread(test_img_folder + '/{}.jpg'.format(img_name)), (64, 64))\n    x_test.append(img)\n    \nfor img_name, _ in tqdm(add_classes.values, miniters=1000):\n    img = cv2.imread(test_img_add_folder + '/{}.jpg'.format(img_name))\n    x_test.append(cv2.resize(img, (64, 64)))\n\nx_test = np.array(x_test, np.float32)\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:01:28.395114Z","iopub.execute_input":"2021-10-20T00:01:28.395405Z","iopub.status.idle":"2021-10-20T00:06:54.178899Z","shell.execute_reply.started":"2021-10-20T00:01:28.395371Z","shell.execute_reply":"2021-10-20T00:06:54.178036Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle = True,random_state=1)\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:09:38.968932Z","iopub.execute_input":"2021-10-20T00:09:38.969392Z","iopub.status.idle":"2021-10-20T00:09:39.130803Z","shell.execute_reply.started":"2021-10-20T00:09:38.969351Z","shell.execute_reply":"2021-10-20T00:09:39.130030Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## **Building Model Architecture**\n\nTo tackle this multi-label problem, a combination of a custom deep CNN architecture along with the pre-trained CNN architecture(VGG16) was implemented in Keras with Tensorflow backend","metadata":{}},{"cell_type":"code","source":"input_size = 64\nchannels = 3\n\nmodel = Sequential()\n\n#input layer\nmodel.add(BatchNormalization(input_shape=(input_size,input_size,channels)))\n\n#CCM_1\nmodel.add(Conv2D(32,kernel_size=(3,3),padding='same',activation='relu'))\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#CCM_2\nmodel.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#CCM_3\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#CCM_4\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Create a feature vector from the CCM_4 final layer\nmodel.add(Flatten())\n\n# Fully Connected (FC) Layer\nmodel.add(Dense(512, activation='relu'))\nmodel .add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Output layer\nmodel.add(Dense(17, activation='sigmoid'))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:09:40.814999Z","iopub.execute_input":"2021-10-20T00:09:40.815543Z","iopub.status.idle":"2021-10-20T00:09:43.143798Z","shell.execute_reply.started":"2021-10-20T00:09:40.815505Z","shell.execute_reply":"2021-10-20T00:09:43.142910Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"out_shape=17\nimport tensorflow.keras as keras\n# Loading the pre-trained VGG16 architecture module\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\n\n\n# Extract the pre - trained architecture\nbase_model = VGG16(input_shape =(input_size,input_size,3),include_top =False,weights ='imagenet')\nbase_model.summary()\n\n# Get the output of the base_model formed above\nx = base_model.output\n# Flatten to obtain a feature vector\nx = Flatten()(x)\n# Connect the feature vector to to the fully connected (FC) layer\nx = Dense (512 , activation ='relu')(x)\n# Form the output label predictions\npredictions = Dense (out_shape, activation ='sigmoid')(x)\nmodel = Model(inputs= base_model.input,outputs = predictions)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:09:43.145630Z","iopub.execute_input":"2021-10-20T00:09:43.146128Z","iopub.status.idle":"2021-10-20T00:09:44.220150Z","shell.execute_reply.started":"2021-10-20T00:09:43.146085Z","shell.execute_reply":"2021-10-20T00:09:44.219507Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:09:44.224012Z","iopub.execute_input":"2021-10-20T00:09:44.225995Z","iopub.status.idle":"2021-10-20T00:09:44.442242Z","shell.execute_reply.started":"2021-10-20T00:09:44.225955Z","shell.execute_reply":"2021-10-20T00:09:44.441287Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Implementing ImageDataGenerator for data augmentation. This is an important technique which reduces \n# overfitting as it generates extra images by flipping, cropping, zooming e,t.c the images. This makes \n# the model have more images to learn from.\n\ntrain_datagen = ImageDataGenerator(featurewise_center=True, \n                                   horizontal_flip=True, \n                                   vertical_flip=True, \n                                   rotation_range=90,\n                                   zoom_range=0.2,\n                                  fill_mode ='reflect'\n                                  )\ntest_datagen = ImageDataGenerator(featurewise_center=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:09:44.447651Z","iopub.execute_input":"2021-10-20T00:09:44.449598Z","iopub.status.idle":"2021-10-20T00:09:44.457251Z","shell.execute_reply.started":"2021-10-20T00:09:44.449560Z","shell.execute_reply":"2021-10-20T00:09:44.456578Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train_datagen.fit(X_train)\ntest_datagen.fit(X_test)\ntrain_it = train_datagen.flow(X_train, y_train, batch_size=128)\ntest_it = test_datagen.flow(X_test, y_test, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:09:44.462158Z","iopub.execute_input":"2021-10-20T00:09:44.464252Z","iopub.status.idle":"2021-10-20T00:09:50.362214Z","shell.execute_reply.started":"2021-10-20T00:09:44.464215Z","shell.execute_reply":"2021-10-20T00:09:50.361448Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:15:31.235242Z","iopub.execute_input":"2021-10-20T00:15:31.235873Z","iopub.status.idle":"2021-10-20T00:16:13.659893Z","shell.execute_reply.started":"2021-10-20T00:15:31.235829Z","shell.execute_reply":"2021-10-20T00:16:13.659035Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Defining other parameters\nepochs=20 # An epoch is one complete pass through the training data, We specify 20 here\noptimizer = keras.optimizers.Adam(learning_rate=0.0001) # Defining our Adam optimizer and learning rate\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizer,\n              metrics=[fbeta_score])\n\ncallback = [EarlyStopping(monitor='val_loss',patience=2,verbose=0),\n             ModelCheckpoint(filepath='weights/best_weights',save_best_only=True,save_weights_only=True)\n            ]","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:09:50.521470Z","iopub.execute_input":"2021-10-20T00:09:50.521942Z","iopub.status.idle":"2021-10-20T00:09:50.536369Z","shell.execute_reply.started":"2021-10-20T00:09:50.521905Z","shell.execute_reply":"2021-10-20T00:09:50.535541Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(train_it,\n                    steps_per_epoch = len(train_it),\n                    validation_data = (test_it),\n                    validation_steps =len(test_it),\n                    epochs =epochs,\n                    callbacks = callback\n                   )","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:10:46.584586Z","iopub.execute_input":"2021-10-20T00:10:46.585437Z","iopub.status.idle":"2021-10-20T00:13:58.363929Z","shell.execute_reply.started":"2021-10-20T00:10:46.585387Z","shell.execute_reply":"2021-10-20T00:13:58.363242Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:23:15.324308Z","iopub.execute_input":"2021-10-20T00:23:15.324942Z","iopub.status.idle":"2021-10-20T00:23:15.628983Z","shell.execute_reply.started":"2021-10-20T00:23:15.324901Z","shell.execute_reply":"2021-10-20T00:23:15.627959Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"\ntest_ = []\ntest_.append (model.predict (x_test, batch_size = 128, verbose = 2))\nresult = np.array(test_[0])\nfor i in range(1,len(test_)):\n    result += np.array(test_)\nresult = pd.DataFrame(result,columns = unique_labels)\n\npred = []\nfor i in tqdm(range(result.shape[0]), miniters=1000):\n    a = result.loc[[i]]\n    a = a.apply(lambda x: x > 0.2, axis=1)\n    a = a.transpose()\n    a = a.loc[a[i] == True]\n    ' '.join(list(a.index))\n    pred.append(' '.join(list(a.index)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:26:53.155671Z","iopub.execute_input":"2021-10-20T00:26:53.156408Z","iopub.status.idle":"2021-10-20T00:26:53.457273Z","shell.execute_reply.started":"2021-10-20T00:26:53.156364Z","shell.execute_reply":"2021-10-20T00:26:53.456297Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"test_df['tags'] = pred\ntest_df.to_csv('amazon.csv', index=False) ","metadata":{"execution":{"iopub.status.busy":"2021-10-20T00:27:48.094349Z","iopub.execute_input":"2021-10-20T00:27:48.094809Z","iopub.status.idle":"2021-10-20T00:27:48.272805Z","shell.execute_reply.started":"2021-10-20T00:27:48.094772Z","shell.execute_reply":"2021-10-20T00:27:48.271827Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}